# -*- coding: utf-8 -*-
"""CNN: Fashion MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wUDwZe2xOPp-GG490_vCbj5lJ9J-hmEv

# **CLASSIFICATION WITH CNN: Fashion MNIST**

Fashion MNIST merupakan dataset berisi gambar baju dan aksesoris, seperti kemeja, tas, sepatu, dan barang mode lainnya. Fashion MNIST berisi 60.000 *training set* dan 10.000 *test set*. Serupa dengan MNIST, setiap data Fashion MNIST merupakan sebuah gambar skala abu (*grayscale*) berukuran 28x28 piksel. Masing-masing data memilki label asosiasinya yang terdiri dari 10 kelas.
"""

#import package

import tensorflow as tf
import keras
from keras.datasets import fashion_mnist 
from keras.layers import Dense, Activation,Dropout, Flatten, Conv2D, MaxPooling2D
from keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam

import numpy as np
import matplotlib.pyplot as plt

"""# **Getting Data**"""

#download the data

from tensorflow.keras.datasets import fashion_mnist
(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()

print('Fashion MNIST Dataset Shape:')
print('X_train: ',str(X_train.shape))
print('Y_train: ',str(Y_train.shape))
print('X_test:  ' ,str(X_test.shape))
print('Y_test:  ' ,str(Y_test.shape))

# read data

sample = X_train[10].reshape(28,28)
print(sample)

#visualize data

plt.imshow(sample, cmap='Greys')

"""#**Data Preparation for Modelling**"""

#We have defined train-test data automatically
#reshaping data

X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)
input_shape = (28, 28, 1)

#normalizing data

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255

print('X_train shape', X_train.shape)
print('X_test shape', X_test.shape)


print('Banyak Gambar di X-train', X_train.shape[0])
print('Banyak Gambar di X-test', X_test.shape[0])

"""#**CNN Modelling (1-Conv)**"""

#built the model

model = Sequential()

#conv_1
model.add(Conv2D(32, kernel_size = (3,3), activation=tf.nn.relu, input_shape = input_shape))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout(0.2))

#input layer from flatten
model.add(Flatten())
model.add(Dense(250, activation=tf.nn.relu))
model.add(Dropout(0.5))
model.add(Dense(10, activation = tf.nn.softmax))

model.summary()

#compiling and fitting the model

adam = Adam(lr=0.001)

model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

CNN = model.fit(X_train, Y_train, epochs = 100, batch_size = 128)

#model accuracy

CNN.history['accuracy'][-1]*100

model.evaluate(X_test, Y_test)

"""#**Visualizing the Result (accuracy & loss)**"""

plt.plot(CNN.history['accuracy'])
plt.plot(CNN.history['loss'])
plt.title('model_accuracy VS model_loss')
plt.ylabel('accuracy/loss')
plt.xlabel('epoch')
plt.legend(['accuracy','loss'], loc='upper right')
plt.savefig('acc_loss_plot_conv1.png')
plt.show()

"""#**Data Testing**"""

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

total_test = len(X_test)
correct_prediction = 0

Y_true = []
Y_pred = []

for i in range (len(X_test)):
  predict = model.predict(X_test[i].reshape(1,28,28,1))
  print(predict)
  
  label = Y_test[i]
  prediction = predict.argmax(axis=-1)
  print('Original label:',str(label))
  print('Original prediction:',str(prediction)+'\n')
  Y_true.append(label)
  Y_pred.append(prediction)
  
  if prediction[0] == label:
    correct_prediction +=1

#evaluation

print('total correct prediction =', str(correct_prediction)+"\n")
print('total incorrect prediction =', str(total_test - correct_prediction)+"\n")
print('accuracy =', accuracy_score(Y_true, Y_pred))
print('classification report: \n', classification_report(Y_true, Y_pred))

#confusion matrix

#y_pred_classes = np.argmax(y_pred, axis = 1)
confusionMatrix = confusion_matrix(Y_true, Y_pred)

import seaborn as sns

f,ax=plt.subplots(figsize=(10,10))
sns.heatmap(confusionMatrix, annot=True, linewidths=0.1, cmap = 'gist_yarg_r', linecolor='black', fmt='.0f', ax=ax)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

#predicting
#For loop to print how many items of each class have been incorrectly estimated

for i in range(len(confusionMatrix)):
    print('Class:',str(i))
    print('Number of Wrong Prediction:', str(sum(confusionMatrix[i])-confusionMatrix[i][i]), 'Out of 1000')